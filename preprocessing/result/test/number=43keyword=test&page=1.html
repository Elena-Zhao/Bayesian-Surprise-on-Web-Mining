the t-test previoushomenext home analysis inferential statistics the t-test the t-test assesses whether the means of two groups are statistically differentfrom each other. this analysis is appropriate whenever you want to compare the means oftwo groups, and especially appropriate as the analysis for the posttest-onlytwo-group randomized experimental design. figure 1. idealized distributions for treated and comparison group posttest values. figure 1 shows the distributions for the treated (blue) and control (green) groups in astudy. actually, the figure shows the idealized distribution -- the actual distributionwould usually be depicted with a histogram or bar graph. thefigure indicates where the control and treatment group means are located. the question thet-test addresses is whether the means are statistically different.what does it mean to say that the averages for two groups are statistically different?consider the three situations shown in figure 2. the first thing to notice about the threesituations is that the difference between the means is the same in all three.but, you should also notice that the three situations don't look the same -- they tellvery different stories. the top example shows a case with moderate variability of scoreswithin each group. the second situation shows the high variability case. the third showsthe case with low variability. clearly, we would conclude that the two groups appear mostdifferent or distinct in the bottom or low-variability case. why? because there isrelatively little overlap between the two bell-shaped curves. in the high variabilitycase, the group difference appears least striking because the two bell-shapeddistributions overlap so much. figure 2. three scenarios for differences between means. this leads us to a very important conclusion: when we are looking at the differencesbetween scores for two groups, we have to judge the difference between their meansrelative to the spread or variability of their scores. the t-test does just this.statistical analysis of the t-testthe formula for the t-test is a ratio. the top part of the ratio is justthe difference between the two means or averages. the bottom part is a measure of thevariability or dispersion of the scores. this formula is essentially another example ofthe signal-to-noise metaphor in research: the differencebetween the means is the signal that, in this case, we think our program or treatmentintroduced into the data; the bottom part of the formula is a measure of variability thatis essentially noise that may make it harder to see the group difference. figure 3 showsthe formula for the t-test and how the numerator and denominator are related to thedistributions. figure 3. formula for the t-test. the top part of the formula is easy to compute -- just find the difference between themeans. the bottom part is called the standard error of thedifference. to compute it, we take the variancefor each group and divide it by the number of people in that group. we add thesetwo values and then take their square root. the specific formula is given in figure 4: figure 4. formula for the standard error of the difference between the means. remember, that the variance is simply the square of the standard deviation.the final formula for the t-test is shown in figure 5: figure 5. formula for the t-test. the t-value will be positive if the first mean is larger than the second and negativeif it is smaller. once you compute the t-value you have to look it up in a table ofsignificance to test whether the ratio is large enough to say that the difference betweenthe groups is not likely to have been a chance finding. to test the significance, you needto set a risk level (called the alpha level). in most socialresearch, the "rule of thumb" is to set the alpha level at .05. this means thatfive times out of a hundred you would find a statistically significant difference betweenthe means even if there was none (i.e., by "chance"). you also need to determinethe degrees of freedom (df) for the test. in the t-test, the degrees of freedom is the sumof the persons in both groups minus 2. given the alpha level, the df, and the t-value, youcan look the t-value up in a standard table of significance (available as an appendix inthe back of most statistics texts) to determine whether the t-value is large enough to besignificant. if it is, you can conclude that the difference between the means for the twogroups is different (even given the variability). fortunately, statistical computerprograms routinely print the significance test results and save you the trouble of lookingthem up in a table.the t-test, one-way analysis of variance (anova) and a form of regression analysis aremathematically equivalent (see the statistical analysis of theposttest-only randomized experimental design) and would yield identical results. previoushomenext copyright ï¿½2006, william m.k. trochim, all rights reserved purchase a printed copy of the research methods knowledge base last revised: 10/20/2006 hometable of contentsnavigatingfoundationssamplingmeasurementdesignanalysisconclusion validitydata preparationdescriptive statisticsinferential statisticsthe t-testdummy variablesgeneral linear modelposttest-only analysisfactorial design analysisrandomized block analysisanalysis of covariancenonequivalent groups analysisregression-discontinuity analysisregression point displacement analysiswrite-upappendicessearch   